# 基于论文《RaaS: Reasoning-Aware Attention Sparsity for Efficient LLM Reasoning》的深入分析（按你要求的数学公式格式）

> 主题：面向长解码推理任务的注意力稀疏化策略 RaaS  
> 关键词：里程碑（Milestone）词元、凤凰（Phoenix）词元、KV Cache、LRU 时间戳、页级缓存、$O(L)$ 时间与内存复杂度

---

## 一、背景

- **长序列推理的瓶颈**
    - 大型语言模型在数学、编程、链式思考等推理任务中产生很长的输出（长解码），导致每步计算注意力需与全部已生成词元交互，单步复杂度约为 $O(N)$，整段生成为 $O(N^2)$。
    - 虽然 KV 缓存避免了重复计算，但缓存与计算仍随历史长度 $N$ 线性增长：时间 $O(N)$，内存 $O(N)$。
- **既有稀疏化方法的三难困境（准确率-时间-内存）**
    - Dense：准确高，但时间/内存均为 $O(N)$。
    - StreamingLLM/Sink：时间/内存降至 $O(L)$，但激进裁剪导致准确率明显下降。
    - H2O：宣称 $O(L)$ 时间/内存，但工程上难以与高效内核兼容，且容易保留“过时信息”影响精度。
    - Quest：时间 $O(L)$ 且精度高，但为保护“凤凰”词元而保留全量 KV，内存仍为 $O(N)$。
- **问题聚焦**
    - 论文专注优化解码阶段（Decode），因为推理场景中解码时间占比可达 99%，且近期推理型方法（如 o1/o3、DeepSeek R1）显著拉长了解码长度。

---

## 二、洞察

- **推理任务的注意力新模式（基于注意力图观察）**
    
    - 在对 Qwen2.5-Math-7B-Instruct 的多层多头注意力进行人工审视后，作者总结两类关键行为：
        - **里程碑（Milestone）词元**：
            - 出现后在一段时间内被频繁关注，随后注意力逐步衰退，并不再回升。
            - 类比推理中的“引理/中间结论”，被后续步骤消费后自然淡出。
            - 注意力图上表现为“逐渐变暗的一列”。
        - **凤凰（Phoenix）词元**：
            - 曾长期低注意力甚至被驱逐，但后来“死而复燃”被再次强关注。
            - 多来自前缀（尤其用户问题），在结论处被回溯引用。
- **经验总结**
    
    - 不当丢弃解码区的“里程碑”会让模型丢失思路、反复重推，精度和长度都会恶化。
    - 凤凰词元主要来自短前缀，因此保留前缀 KV 可在不增加太多预算的同时保护关键语义。
    - 预算充足（如 $L\ge 512$）时，解码区几乎不再出现凤凰；预算很小（如 $L=64$）时，凤凰仍可能出现。

---

## 三、设计思想

- **目标**：兼顾高准确率、$O(L)$ 时间复杂度、$O(L)$ 内存复杂度，突破“三难困境”。
    
- **两大策略**
    
    1. **解码区里程碑保活（LRU 近似）**
        - 用“最近被使用”的信号近似里程碑活跃度：每步将注意力分数高于“中位数”的页面标记为被使用并更新时间戳；缓存满时按 LRU 淘汰最旧者。
        - 真正的里程碑会在生命期内持续刷新时间戳，变“过时”后才自然被淘汰。
    2. **前缀区全保留**
        - 不淘汰前缀（提示）KV，避免丢失凤凰词元。
        - 推理任务里前缀较短，此举以有限成本保护关键信息。
- **工程化实现：页级 RaaS**
    
    - 为兼容 FlashAttention 等高效内核，采用页级管理（与 vLLM 一致，典型 `page_size=16`）。
    - 为每页计算代表注意力分数（与 Quest 一致的代表法），以此更新页的时间戳；执行注意力时仍利用紧凑的页结构与高效内核。

---

## 四、设计的数学式推导与分析

- **复杂度分析**
    
    - 设总序列长度为 $N$，缓存预算为 $L$（上限页数或等效词元数），且 $L\ll N$：
        - Dense：
            - 单步复杂度 $O(N)$，全程 $O(N^2)$；
            - 内存 $O(N)$。
        - Quest：
            - 单步仅与至多 $L$ 个页交互，复杂度 $O(L)$，全程 $O(NL)$；
            - 但保留全量 KV，内存 $O(N)$。
        - RaaS：
            - 单步 $O(L)$，全程 $O(NL)$；
            - 仅保留活跃的解码页与全部前缀页，峰值内存 $O(L)$。
- **阈值选择（中位数）的统计动机**
    
    - 每步将注意力分数集合 $S={s_i}$ 按中位数 $\mathrm{median}(S)$ 划分，上半分位页被视为“被使用”并更新其时间戳。
    - 若阈值更高，会保活过多页、降低区分度；阈值更低则易误删正在崛起的新里程碑。实验显示采用中位数（等价于 $r=0.5$）在多模型/数据上鲁棒。
- **里程碑与凤凰的操作性定义**
    
    - 里程碑页：在一段时间内频繁进入“上半分位”，随后注意力单调走低且不再回升。
    - 凤凰页：在预算 $L$ 约束下被淘汰后，随后又多次进入“上半分位”。

---

## 五、应用场景

- **最契合**
    
    - 推理型长解码：GSM8K、MATH、AIME 等数学推理，复杂代码综合推导，Research-style CoT/self-refine/deliberate。
    - 前缀短、解码长的问答：例如“简短题干 + 多步推理”。
- **需注意或组合的场景**
    
    - 长前缀（RAG/多证据/工具调用）：前缀全保会占据大量预算，压缩解码区可用页数。
        - 建议：Prefill 用 Quest（从前缀中挑关键页），Decode 用 RaaS（里程碑保活）。

---

## 六、效果评估（论文实验结论）

- **准确率 vs. 缓存预算**
    
    - RaaS 与 Quest 在多数预算下准确率接近 Dense；预算极小（如 $L=64$）时，RaaS 因“前缀全保”导致解码页不足，略逊于 Quest。
    - Sink/H2O 在推理任务上显著下降：Sink 静态裁剪误删关键步骤；H2O 的累计打分偏好“旧信息”，易错保、误删。
- **延迟与内存随解码长度变化**
    
    - 延迟：Dense 随长度近似二次增长，RaaS/Quest 近似线性（单步 $O(L)$）。
    - 内存：Dense 与 Quest 线性增长；RaaS 达到预算后平台化，体现 $O(L)$ 内存优势。
- **微基准与超参**
    
    - 误删里程碑会造成“失忆式重推”，显著拉长输出且错误率上升。
    - 超参数 $r$（上半分位阈值）默认 $0.5$ 表现稳定。
- **实现与环境**
    
    - 约 2k 行 Python 实现；A100-80GB；与 vLLM/SGLang 风格页级缓存兼容；`page_size=16`，$r=0.5$。

---

## 七、综合评估（优缺点与建议）

- **优点**
    
    - 在推理长解码任务中，实现高准确率与 $O(L)$ 时间/内存的统一。
    - 语义解释性强：与“中间引理被逐步消费”的认知过程一致。
    - 工程友好：页级代表分数与高效内核兼容，易于在现有推理服务中落地。
    - 峰值内存平台化：利于提升吞吐、降低成本。
- **缺点/限制**
    
    - 注意力模式的统计证据仍偏经验性，跨模型大规模量化分析可进一步加强。
    - 对短前缀-长解码的推理任务最优；长前缀需要与 Quest 组合以避免预算被前缀占满。
    - 极小预算下的权衡：前缀全保会压缩解码页，准确率可能受损。
    - 超参敏感度：尽管 $r=0.5$ 较鲁棒，特定模型/任务仍需微调。
- **部署与调参建议**
    
    - 将 RaaS 作为“Decode-Only”策略；Prefill 采用 Quest，形成混合流水线。
    - 预算 $L$ 建议优先尝试 $512!\sim!1024$ 页（或等效词元），通常接近 Dense 精度。
    - 联合优化：可叠加 KV 量化（如 KIVI、ZeroQuant）进一步压缩内存；监控“异常长尾输出”以捕捉潜在误删里程碑。

---

## 八、关键公式与伪代码要点

- **复杂度对比（设序列长 $N$、预算 $L$）**
    
    - Dense：单步 $O(N)$，总计 $O(N^2)$，内存 $O(N)$。
    - Quest：单步 $O(L)$，总计 $O(NL)$，但内存 $O(N)$。
    - RaaS：单步 $O(L)$，总计 $O(NL)$，内存 $O(L)$。
- **RaaS 的核心时间戳更新规则（解码步）**
    
    - 对每步各页的注意力代表分数集合 $S={s_i}$，计算 $\mathrm{median}(S)$。
    - 若 $s_i \ge \mathrm{median}(S)$，则将页 $i$ 的时间戳更新为当前步编号（标记为“最近使用”）。
    - 若缓存已满，驱逐时间戳最旧的可驱逐页；前缀页标记为“不可驱逐”。
- **页级代表分数**
    
    - 对每页选取代表 Key/Value（如页内首个或汇聚向量），计算与当前 Query 的注意力得分，作为该页的代表分数，用于排序/保活。

---

## 九、与相关工作的关系

- **Quest**：同样使用页级代表分数；但 Quest 为保护凤凰而保留全量 KV（内存 $O(N)$），RaaS 通过“前缀全保 + 解码里程碑保活”实现内存 $O(L)$。
- **H2O**：累计历史注意力易“抱旧”导致错保；RaaS 强调“最近使用”的动态性，能更快适应语义迁移。
- **StreamingLLM/Sink**：静态窗口/锚点缺乏语义感知，推理任务上误删率高；RaaS 以注意力统计驱动、可解释的动态保活策略更稳健。

---

## 十、结论

RaaS 把推理过程中“中间引理被消费后淡出”的认知规律，转化为页级 KV 缓存的动态管理：

- 通过“中位数阈值 + LRU 时间戳”保活里程碑页，
- 通过“前缀全保”规避凤凰风险，
- 在推理类长解码中实现接近 Dense 的准确率，同时将时间与内存控制在 $O(L)$。  
    工程上建议与 Quest 的前缀选择结合，以覆盖长前缀场景；在 $L\ge 512$ 的预算下，RaaS 往往能以低成本获得高精度与高吞吐。

如果你要把 RaaS 集成进 vLLM/SGLang 或自研引擎，我可以按你的资源预算给出详细的参数表与观测指标，包括如何选择 $L$ 与 $r$、页大小、以及与量化/分片/流水线并发的兼容方案。

# 设计思想（强化加强版）：机制、公式与逐步执行流程（按你要求的数学格式：行内用$...$，跨行/独立公式用$$...$$）

> 目标：在保持推理精度的前提下，将解码阶段的时间与内存控制在 $O(L)$，其中 $L$ 为可控的缓存预算（页或等效词元上限）。本节围绕 RaaS 的核心机制，给出更细致的设计逻辑、关键公式推导、以及带数值的逐步执行案例。

---

## 1. 术语说明与问题建模

- 序列与分区
    - 前缀（prefill）长度：$N_p$
    - 解码（decode）步数：$T$（动态增长）
    - 总长度：$N=N_p+T$
- 页级缓存（与 vLLM 一致）
    - 页大小：$\text{page\_size} = P$（典型 $P=16$）
    - 第 $j$ 页的键/值张量：$K_j \in \mathbb{R}^{P \times d_k}$，$V_j \in \mathbb{R}^{P \times d_v}$
    - 缓存预算（页数上限）：$L$
- 注意力与打分（简化为单头）
    - 当前步查询：$q_t \in \mathbb{R}^{d_k}$
    - 标准缩放点积注意力对单 token 的打分：$\alpha_i = \frac{q_t^\top k_i}{\sqrt{d_k}}$

---

## 2. 页级代表分数：从 token 到页的可比尺度

为了兼容高效注意力内核与页式管理，RaaS对“页”而非每个token进行存活管理，为此需将页内token的注意力打分聚合为“代表分数” $s_j$，常见两种聚合：

- 最大池化（偏“召回关键点”） $$ s_j^{\max} = \max_{i \in \text{page } j} \left( \frac{q_t^\top k_i}{\sqrt{d_k}} \right) $$
    
- 均值池化（偏“稳健抗噪”） $$ s_j^{\text{mean}} = \frac{1}{P}\sum_{i \in \text{page } j} \left( \frac{q_t^\top k_i}{\sqrt{d_k}} \right) $$
工程上与Quest一致地可用“代表 key”近似（缓存页内代表 Key），本分析默认使用 $s_j = s_j^{\max}$，也可采用加权混合以折中： $$ s_j = \alpha \cdot s_j^{\max} + (1-\alpha)\cdot s_j^{\text{mean}},\quad \alpha \in [0,1] $$

---

## 3. 中位数阈值与“最近使用”判定（识别活跃里程碑）

在步$t$对所有在库页计算代表分数集合 $S_t={s_1,\dots,s_M}$（$M$ 为当前缓存中的页数），以中位数作为阈值： $$ \theta_t=\mathrm{median}(S_t) $$
将分数不低于阈值的页视为“被使用”（近似活跃里程碑）： $$ \text{used}(j,t)=\mathbb{I}[,s_j \ge \theta_t,] $$

以“被使用”为触发信号刷新页的 LRU 时间戳（最近使用时间）： $$ \text{ts}(j) \leftarrow \begin{cases} t, & \text{若 } \text{used}(j,t)=1 \ \text{ts}(j), & \text{否则} \end{cases} $$

直觉：真正的“里程碑”页在“生命期”内会频繁落入上半分位（$s_j \ge \theta_t$），从而连续刷新 $\text{ts}(j)$；当其价值被后续步骤消费完后，$s_j$ 会下降并停止刷新，继而在竞争中自然淘汰。

## 4. 前缀全保与可驱逐集合（规避凤凰风险）

- 将所有Prefill页标记为“不可驱逐”： $$ j \in \mathcal{P} \Rightarrow \text{evictable}(j)=0 $$
    
- 仅Decode区页可被驱逐： $$ j \in \mathcal{D} \Rightarrow \text{evictable}(j)=1 $$
动机：凤凰页主要来自前缀（例如用户问题陈述），在最终总结时可能被回溯强引用，前缀全保以小成本（前缀相对短）避免“晚期回看失败”的重大精度损失。

---

## 5. 缓存满载时的 LRU 驱逐策略（只淘汰解码页）

当写入新解码页将超出预算 $L$ 时，从可驱逐集合（解码页）中选择时间戳最旧者淘汰： $$ j^\star = \arg\min_{j \in \mathcal{D},, \text{evictable}(j)=1} \text{ts}(j) $$

随后在该位置写入新页，并将其时间戳初始化为 $t$，这相当于保持“最近使用”的解码页存活，符合“里程碑保活”的目标。

---

## 6. 稀疏读写与复杂度

- 单步注意力仅与至多 $L$ 个页交互：时间复杂度 $O(L)$
- 新页写入引发的驱逐与分配摊还为 $O(1)$
- 解码阶段总复杂度（$T$ 步）：$O(TL)=O(NL)$
- 峰值内存受页上限约束：$O(L)$

对比 Dense（单步 $O(N)$、总 $O(N^2)$、内存 $O(N)$），RaaS 将解码阶段的计算与内存成本均绑定在常数 $L$ 上。

---

## 7. 逐步骤执行流程（1、2、3...带数值小案例）

设定一个可复现实例，展示从第一个解码步到触发驱逐的全过程。

- 假设参数：
    
    - 页大小 $P=4$（示意）
    - 预算 $L=6$
    - 前缀长度 $N_p=10$，分页为 $\lceil 10/4 \rceil = 3$ 页：$\mathcal{P}={P1,P2,P3}$（不可驱逐）
    - 初始解码集合 $\mathcal{D}=\varnothing$，可用于解码的页预算 $= L - |\mathcal{P}| = 3$
- 记号：
    
    - 当前步查询 $q_t$
    - 页代表分数 $s_j$
    - 中位数阈值 $\theta_t$
    - 时间戳 $\text{ts}(j)$

---

### 1）t=1：初始化与第一个解码 token

- 计算前缀页代表分数（示例）： $$ s_{P1}=1.2,\quad s_{P2}=0.5,\quad s_{P3}=0.9 $$
- 中位数阈值： $$ \theta_1=\mathrm{median}({1.2,0.5,0.9})=0.9 $$
- 使用判定与时间戳更新：
    - $P1: 1.2 \ge 0.9 \Rightarrow \text{ts}(P1)\leftarrow 1$
    - $P2: 0.5 < 0.9 \Rightarrow \text{ts}(P2)$ 不变（保持 0）
    - $P3: 0.9 \ge 0.9 \Rightarrow \text{ts}(P3)\leftarrow 1$
- 写入新解码页 $D1$（未超限）并设置 $\text{ts}(D1)\leftarrow 1$

当前：

- 前缀：$P1(\text{ts}=1), P2(0), P3(1)$
- 解码：$D1(1)$

---

### 2）t=2：第二个解码 token

- 代表分数（示例）： $$ s_{P1}=0.8,\ s_{P2}=0.6,\ s_{P3}=0.7,\ s_{D1}=1.1 $$
- 阈值： $$ \theta_2=\mathrm{median}({0.8,0.6,0.7,1.1})=\frac{0.75+0.8}{2}=0.775 $$
- 更新时间戳：
    - $P1: 0.8 \ge 0.775 \Rightarrow \text{ts}(P1)\leftarrow 2$
    - $P2: 0.6 < 0.775 \Rightarrow$ 不变
    - $P3: 0.7 < 0.775 \Rightarrow$ 不变
    - $D1: 1.1 \ge 0.775 \Rightarrow \text{ts}(D1)\leftarrow 2$
- 写入 $D2$，$\text{ts}(D2)\leftarrow 2$

当前：

- 前缀：$P1(2), P2(0), P3(1)$
- 解码：$D1(2), D2(2)$

---

### 3）t=3：第三个解码 token

- 代表分数（示例）： $$ s_{P1}=0.4,\ s_{P2}=0.3,\ s_{P3}=0.5,\ s_{D1}=0.6,\ s_{D2}=1.3 $$
- 阈值： $$ \theta_3=\mathrm{median}({0.4,0.3,0.5,0.6,1.3})=0.5 $$
- 更新时间戳：
    - $P3: 0.5 \ge 0.5 \Rightarrow \text{ts}(P3)\leftarrow 3$
    - $D1: 0.6 \ge 0.5 \Rightarrow \text{ts}(D1)\leftarrow 3$
    - $D2: 1.3 \ge 0.5 \Rightarrow \text{ts}(D2)\leftarrow 3$
    - $P1,P2$ 不变
- 写入 $D3$，$\text{ts}(D3)\leftarrow 3$

当前：

- 前缀：$P1(2), P2(0), P3(3)$
- 解码：$D1(3), D2(3), D3(3)$

---

### 4）t=4：第四个解码 token（首次触发驱逐）

此时已有 6 页（达到 $L$）。再写新页需先驱逐 1 个解码页。

- 代表分数（示例）： $$ s_{P1}=0.2,\ s_{P2}=0.1,\ s_{P3}=0.3,\ s_{D1}=0.7,\ s_{D2}=0.9,\ s_{D3}=1.0 $$
- 阈值： $$ \theta_4=\mathrm{median}({0.2,0.1,0.3,0.7,0.9,1.0})=\frac{0.5+0.7}{2}=0.6 $$
- 更新时间戳：
    - $D1,D2,D3$ 均 $\ge 0.6$，因此 $\text{ts}(D1),\text{ts}(D2),\text{ts}(D3)\leftarrow 4$
    - 前缀页不可驱逐，时间戳不重要
- 写入 $D4$ 前先驱逐：
    - 可驱逐集合为 ${D1,D2,D3}$，此时三者并列最“新”（$\text{ts}=4$），按先入先出或索引最小驱逐 $D1$
    - 驱逐 $D1$，写入 $D4$，$\text{ts}(D4)\leftarrow 4$

当前：

- 前缀：$P1(2), P2(0), P3(3)$
- 解码：$D2(4), D3(4), D4(4)$

说明：RaaS 优先保留最近被使用的解码页；旧的“里程碑”在贡献衰退后会被自然替换。

---

## 8. 进一步的数学分析与性质

- 单步复杂度与总复杂度 $$ \text{Time}_\text{per-step} = O(L),\quad \text{Time}_\text{decode} = O(TL)=O(NL) $$
    
- 峰值内存 $$ \text{Mem}_\text{peak} = O(L) $$
    
- 里程碑生存的启发式“充分条件”
    
    - 若某页在窗口长度 $\Delta$ 内有 $m$ 次落入上半分位（$s_j \ge \theta_t$），且在 $\Delta$ 内可驱逐页的竞争度不超过预算 $L$ 所允许的刷新频率，则该页的 $\text{ts}(j)$ 将被多次刷新，存活至其语义作用期结束的概率较高。
- 凤凰规避（由前缀全保保证）
    
    - 来自前缀的“晚期回溯引用”无需担忧被淘汰，从而避免推理尾段引用失败。

---

## 9. 实战建议与可调超参

- 代表分数的聚合
    - 默认 $s_j^{\max}$；若噪声导致误保增多，可采用混合 $s_j=\alpha s_j^{\max}+(1-\alpha)s_j^{\text{mean}}$ 并调 $\alpha$。
- 分位阈值
    - 默认中位数 $q=0.5$；若预算紧张且需更快淘汰旧页，可略抬高 $q$（如 $0.6$）；若出现误删新里程碑，降低 $q$（如 $0.4$）。
- 页大小 $P$
    - 与内核实现相关（vLLM 常用 $16$）；更大 $P$ 减元数据开销，但页内异质性上升时 $s_j$ 的代表性可能变差。
- 预算 $L$
    - 推理任务建议从 $L \in [512, 1024]$ 起测，通常能在接近 Dense 精度下获得显著的时延与内存优势。

---

## 10. 伪代码（Decode 阶段的页级 RaaS）

```python
# inputs:
#   PAGES_P: list of prefix pages (non-evictable)
#   L: page budget, P: page size (e.g., 16)
# state:
pages = list(PAGES_P)           # current pages in cache
ts = {j: 0 for j in pages}      # last-used timestamp
evictable = {j: (j not in PAGES_P) for j in pages}

for t in range(1, T+1):
    q_t = get_query(t)

    # 1) representative score per page
    S = {}
    for j in pages:
        S[j] = rep_score(q_t, K_page=j)  # e.g., max-pooled scaled dot-product

    # 2) median threshold
    theta = median(list(S.values()))

    # 3) recent-use update
    for j in pages:
        if S[j] >= theta:
            ts[j] = t

    # 4) allocate new decode page if needed
    if need_new_page(t):
        if len(pages) == L:
            cand = [j for j in pages if evictable.get(j, True)]
            j_star = min(cand, key=lambda j: ts[j])  # LRU
            evict(j_star); pages.remove(j_star)
        new_page = alloc_page(t)
        pages.append(new_page)
        ts[new_page] = t
        evictable[new_page] = True

    # 5) attention compute with current pages (O(L))
    y_t = attend(q_t, pages)
    emit(y_t)
```

实现提示：

- 多头注意力可对每头计算代表分数并取平均/最大聚合，再进入步骤 2。
- 为效率可对每页缓存代表 key，避免每步扫描页内全部 token。
- 若底层采用页式 KV 管理（如 vLLM），`alloc_page/evict` 与页表同步。

---

## 11. 结合真实任务的执行轨迹（数学题推理）

- 场景：简短题干（前缀约 300 tokens，约 19 页）+ 长解码（1500 tokens，约 94 页），$L=64, P=16$。
- 动态：
    - 早期：题干页（前缀）频繁进入上半分位，被持续刷新时间戳，支撑中间引理构建。
    - 中期：早期草算页的 $s_j$ 逐步下降；新的中间结论页成为“里程碑”，时间戳持续刷新。
    - 末期：最终汇总/验证阶段再次回看题干；由于前缀不可驱逐，能稳定完成“回溯引用”，减少答非所问与遗忘条件。
- 调参：
    - 若出现异常长尾输出与反复自我纠错，常是“误删里程碑”的信号；可降低阈值 $q$ 或增大 $L$。
    - 若时延仍偏高，可略提升 $q$ 或减少代表分数的计算开销（如更激进的代表 key 近似）。

---

## 12. 小结（机制因果链与可验证指标）

- 因果链
    
    - 中位数阈值 → 稳定识别“当前上半分位”页
    - LRU 时间戳 → 让活跃里程碑持续保活、旧页自然淘汰
    - 前缀全保 → 消除“凤凰回溯失配”的主要来源
    - 页级代表分数 → 与高效内核兼容，保持单步 $O(L)$
- 监控与验证
    
    - 解码步时均值/P95 应随长度近线性增长
    - 峰值页数平台化在 $L$ 附近
    - 每步“被使用”页比例约 50%
    - 误删检测：被驱逐页后续频繁高分重现的比例上升

---

如果你愿意，我可以基于你的具体模型与工作负载（前缀分布、目标解码长度、GPU 型号）给出一套 $L$、$P$、分位阈值 $q$、代表分数聚合 $\alpha$ 的推荐配置，并附带 A/B 实验设计与观测指标表。